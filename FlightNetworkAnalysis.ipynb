{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehark56/FlightNetworkAnalysis/blob/main/FlightNetworkAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUuWmJegp-W3"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIyJzllip-W4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdRKouexp-W5"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "G = nx.MultiDiGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnbvMnFup-W5"
      },
      "source": [
        "Read CSV File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oX3bsIap-W5"
      },
      "outputs": [],
      "source": [
        "my_dataset = pd.read_csv('airlinedelaycauses_DelayedFlights.csv',  low_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w70uokIqp-W6"
      },
      "source": [
        "Print Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JYrCeFCp-W6"
      },
      "outputs": [],
      "source": [
        "my_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvI2kVYMp-W6"
      },
      "source": [
        "DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrKgmRQcp-W7"
      },
      "source": [
        "Column Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ1npNEPp-W7"
      },
      "outputs": [],
      "source": [
        "my_dataset = my_dataset.drop(['Year','Month','DayofMonth','CRSDepTime','CRSArrTime','CRSElapsedTime','ArrDelay','DepDelay','Cancelled','CancellationCode','Diverted','CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay','TaxiIn','TaxiOut','DayOfWeek'],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MMSM0QYp-W7"
      },
      "outputs": [],
      "source": [
        "my_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu6KeBirp-W7"
      },
      "source": [
        "Drop Null Value Rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vdHzNdVp-W7"
      },
      "outputs": [],
      "source": [
        "my_dataset = my_dataset.dropna()\n",
        "#thresh=half_count,\n",
        "my_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f95j73D5p-W7"
      },
      "source": [
        "Store Unique Airports Names In A List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfLB4uRsp-W7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # Import the pandas library\n",
        "\n",
        "uniqueValues = pd.concat([my_dataset['Origin'], my_dataset['Dest']]).unique()\n",
        "print(uniqueValues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VXvr7gUp-W8"
      },
      "outputs": [],
      "source": [
        "print(type(uniqueValues))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rjb8Ujlp-W8"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import networkx as nx\n",
        "\n",
        "# Initialize the graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Load uniqueValues from file or ensure it's correctly defined\n",
        "with open('airport.pkl', 'rb') as m:\n",
        "    uniqueValues = pickle.load(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW1P8OsMp-W8"
      },
      "source": [
        "Declaring Node For Each Airport In The List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiS8RR6fp-W8"
      },
      "outputs": [],
      "source": [
        "for airport in uniqueValues:\n",
        "    G.add_node(airport, name=airport)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x16sGLtPp-W8"
      },
      "source": [
        "Total No Of Nodes/Airports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbHAe6S8p-W8"
      },
      "outputs": [],
      "source": [
        "print(G.number_of_nodes())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVEAwUNKp-W8"
      },
      "source": [
        "Graphical Representation Of Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6BVdu6pp-W8"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming G is your original graph\n",
        "\n",
        "# Specify the airport code of interest\n",
        "target_airport = 'MHT'  # Replace 'ATL' with your desired airport code\n",
        "\n",
        "# Get the neighbors of the target airport\n",
        "neighbors = list(G.neighbors(target_airport))\n",
        "\n",
        "# Include the target airport itself in the list of nodes to visualize\n",
        "nodes_to_draw = neighbors + [target_airport]\n",
        "\n",
        "# Create a subgraph with just these nodes\n",
        "subgraph = G.subgraph(nodes_to_draw)\n",
        "\n",
        "# Draw the subgraph\n",
        "plt.figure(figsize=(10, 10))  # Adjust figure size as needed\n",
        "nx.draw(subgraph, with_labels=True, node_size=500, node_color='skyblue', font_size=10, font_color='black', edge_color='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AMHW3Fpp-W8"
      },
      "source": [
        "Making Edges Between The Airports With Weights As Min Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVoqi0Mep-W9"
      },
      "outputs": [],
      "source": [
        "for flight in my_dataset.index:\n",
        "    # print (my_dataset['FlightNum'][train])\n",
        "    # G.add_edge(my_dataset['Origin'], my_dataset['Dest'], weight=my_dataset['ActualElapsedTime'])\n",
        "    # G.add_edge(my_dataset['Origin'][train], my_dataset['Dest'][train], l=my_dataset['ActualElapsedTime'][train],flight=my_dataset['FlightNum'][train])\n",
        "\n",
        "    if not G.has_edge(my_dataset['Origin'][flight], my_dataset['Dest'][flight]):\n",
        "        G.add_edge(my_dataset['Origin'][flight], my_dataset['Dest'][flight], l=my_dataset['ActualElapsedTime'][flight],flight=my_dataset['FlightNum'][flight])\n",
        "    elif G[my_dataset['Origin'][flight]][my_dataset['Dest'][flight]][0][\"l\"] > my_dataset['ActualElapsedTime'][flight]:\n",
        "        G[my_dataset['Origin'][flight]][my_dataset['Dest'][flight]][0][\"l\"] = my_dataset['ActualElapsedTime'][flight]\n",
        "        G[my_dataset['Origin'][flight]][my_dataset['Dest'][flight]][0][\"flight\"] = my_dataset['FlightNum'][flight]\n",
        "\n",
        "\n",
        "\n",
        "# import networkx as nx\n",
        "# G = nx.MultiDiGraph()\n",
        "# G.add_edge(\"A\", \"B\", weight=3)\n",
        "# G.add_edge(\"A\", \"C\", weight=10)\n",
        "# G.edges(data=True)\n",
        "# check if edge exists\n",
        "\n",
        "\n",
        "# if G.has_edge(\"A\", \"B\") and G[\"A\"][\"B\"][0][\"weight\"] > 5:\n",
        "#     G[\"A\"][\"B\"][0][\"weight\"] = 5\n",
        "# elif not G.has_edge(\"A\", \"B\"):\n",
        "#     G.add_edge(\"A\", \"B\", weight=5)\n",
        "    # continue\n",
        "# nx.shortest_path(G, \"A\", \"B\", weight=\"weight\")\n",
        "# G.edges(data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7p-CPkep-W9"
      },
      "outputs": [],
      "source": [
        "G.number_of_edges()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxZ_BwfFp-W9"
      },
      "outputs": [],
      "source": [
        "G.number_of_nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvIzKHbep-W9"
      },
      "source": [
        "Graphical Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meaR3G1Gp-W9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "# Use spring_layout with increased 'k' to spread nodes out\n",
        "pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
        "\n",
        "# Increase figure size for better visibility\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "# Draw the graph with labels and adjust node size and font size\n",
        "nx.draw(G, pos, with_labels=True, node_size=50, font_size=8, edge_color='gray', node_color='blue')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si0NhVDLp-W9"
      },
      "outputs": [],
      "source": [
        "G.number_of_edges()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArTlN9dSp-W9"
      },
      "source": [
        "Centrality Measures For Each Nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UEwAPLOp-W9"
      },
      "source": [
        "Degree Centrality (DC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDo93-N0p-W9"
      },
      "outputs": [],
      "source": [
        "nx.degree_centrality(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h1i0WBMp-W9"
      },
      "source": [
        "Betweenness Centrality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOcl2xrZp-W9"
      },
      "outputs": [],
      "source": [
        "nx.betweenness_centrality(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwXh6rOqp-W9"
      },
      "source": [
        "Top 10 Airports With Highest Degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23FORC1Ip-W9"
      },
      "outputs": [],
      "source": [
        "l=list(G.degree(list(G.nodes())))\n",
        "l.sort(key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhZBy7vzp-W9"
      },
      "outputs": [],
      "source": [
        "\n",
        "l[:10] #top 10 nodes with highest degree (stations with most number of flights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cNUPv1Lp-W-"
      },
      "source": [
        "**Flight**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj_zIHmKp-W-"
      },
      "outputs": [],
      "source": [
        "G.edges('ATL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4mOJSCnp-W-"
      },
      "outputs": [],
      "source": [
        "G.degree('ATL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy8Gm1xRp-W-"
      },
      "outputs": [],
      "source": [
        "for i in uniqueValues:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh7wY2DKp-W-"
      },
      "source": [
        "Airport With Their Degrees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMsqW8t3p-W-"
      },
      "outputs": [],
      "source": [
        "dict={}\n",
        "for i in uniqueValues:\n",
        "    dict[i]=G.degree(i)\n",
        "dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApC5QRhIp-W-"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(nx.adjacency_matrix(G, weight=\"l\").todense(), index=G.nodes(), columns=G.nodes())\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENggzI3Lp-W-"
      },
      "source": [
        "Saving Shorted Distance Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awMJapzKp-W-"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "dbfile = open('df', 'ab')\n",
        "pickle.dump(df, dbfile)\n",
        "dbfile.close()\n",
        "\n",
        "# dbfile = open('examplePickle', 'rb')\n",
        "# G = pickle.load(dbfile)\n",
        "# dbfile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogRNjbF8p-W-"
      },
      "outputs": [],
      "source": [
        "dbfile = open('df', 'rb')\n",
        "df2 = pickle.load(dbfile)\n",
        "dbfile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ey6grHap-W-"
      },
      "outputs": [],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9ElMGwJp-W-"
      },
      "outputs": [],
      "source": [
        "o=nx.shortest_path_length(G, source=\"ATL\", target=\"IND\", weight=\"l\")\n",
        "o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgjW87kTp-W-"
      },
      "outputs": [],
      "source": [
        "shortestPathByDistanceTimeDF =pd.DataFrame( index=G.nodes(), columns=G.nodes())\n",
        "for i in G.nodes():\n",
        "    for j in G.nodes():\n",
        "        if i==j:\n",
        "            continue\n",
        "        lst=[]\n",
        "        # try:\n",
        "        #     lst.append(nx.shortest_path_length(G, source=i, target=j, weight=\"distance\"))\n",
        "        # except nx.NetworkXNoPath:\n",
        "        #     lst.append(None)\n",
        "        try:\n",
        "            lst.append(nx.shortest_path_length(G, source=i, target=j, weight=\"l\"))\n",
        "        except nx.NetworkXNoPath:\n",
        "            lst.append(None)\n",
        "\n",
        "        shortestPathByDistanceTimeDF.loc[i,j] = lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGyJwqY0p-W-"
      },
      "source": [
        "SHORTEST PATH DISTANCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm_euuRfp-W-"
      },
      "outputs": [],
      "source": [
        "shortestPathByDistanceTimeDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n-31VMVp-W_"
      },
      "source": [
        "SHORTEST PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CtoWktMp-W_"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "# Check if the nodes exist in the graph, considering case sensitivity\n",
        "source_node = \"lmt\"\n",
        "target_node = \"pir\"\n",
        "\n",
        "# Check if both source and target nodes are in the graph\n",
        "if source_node in G.nodes() and target_node in G.nodes():\n",
        "    try:\n",
        "        # Calculate the shortest path using lowercase node names\n",
        "        p = nx.shortest_path(G, source=source_node, target=target_node, weight=\"l\")\n",
        "        print(f\"The shortest path from {source_node} to {target_node} is: {p}\")\n",
        "    except nx.NetworkXNoPath:\n",
        "        print(f\"No path exists between {source_node} and {target_node}.\")\n",
        "    except nx.NodeNotFound as e:\n",
        "        print(f\"NodeNotFound error: {e}\")\n",
        "else:\n",
        "    missing_nodes = [node for node in [source_node, target_node] if node not in G.nodes()]\n",
        "    print(f\"Node(s) not found in the graph: {', '.join(missing_nodes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJJ9CxBdp-W_"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('graph.pkl', 'wb') as m:\n",
        "    pickle.dump(G, m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faEjsnUyp-W_"
      },
      "outputs": [],
      "source": [
        "n = 20\n",
        "k = 4\n",
        "p = 0.3\n",
        "seed = 42\n",
        "\n",
        "G8 = nx.watts_strogatz_graph(n, k, p, seed=seed)\n",
        "\n",
        "# Draw the graph using the default layout\n",
        "nx.draw(G8, with_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MMO7wmTp-W_"
      },
      "outputs": [],
      "source": [
        "nodes = [1, 2, 3, 4, 5]\n",
        "# Create a subgraph from the selected nodes\n",
        "subgraph = G.subgraph(nodes)\n",
        "\n",
        "# Draw the original graph and the subgraph side by side\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
        "\n",
        "nx.draw(G, ax=ax1, with_labels=True)\n",
        "ax1.set_title('Original Graph')\n",
        "\n",
        "nx.draw(subgraph, ax=ax2, with_labels=True)\n",
        "ax2.set_title('Subgraph')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVRIvQyZp-W_"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "G_simple = nx.Graph(G)\n",
        "\n",
        "# Find the cycle basis of the graph\n",
        "cycle_basis = nx.cycle_basis(G_simple, root=\"ATL\")\n",
        "\n",
        "# Print the cycle basis\n",
        "print(len(cycle_basis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB2uZmpDp-W_"
      },
      "outputs": [],
      "source": [
        "G0 = nx.Graph(G)\n",
        "efficiency = nx.efficiency(G0, \"ATL\", \"YUM\")\n",
        "\n",
        "# Print the efficiency\n",
        "print(efficiency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN0T8omyp-W_"
      },
      "outputs": [],
      "source": [
        "#CSV To Dataframe\n",
        "import pandas as pd\n",
        "station_code = pd.read_csv('US-Airport-Codes.csv',  low_memory=False)\n",
        "station_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd9L3dLtp-W_"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "airport_name={}\n",
        "with open ('US-Airport-Codes.csv', mode='r') as f:\n",
        "    data = csv.reader(f)\n",
        "    airport_name={rows[1].strip():rows[0].strip() for rows in data}\n",
        "print(type(airport_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Er-N0vyp-W_"
      },
      "outputs": [],
      "source": [
        "print(airport_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_31_dZYnp-W_"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('airport_code.pkl', 'wb') as f:\n",
        "    pickle.dump(airport_name, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn8NPgjwp-W_"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "airport_name = {}\n",
        "with open('US-Airport-Codes.csv', mode='r') as f:\n",
        "    data = csv.reader(f)\n",
        "    # Skip the header row\n",
        "    next(data)\n",
        "    airport_name = {rows[1].strip(): rows[0].strip() for rows in data}\n",
        "\n",
        "print(airport_name['ATL'])  # Access without trailing space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCvqrkuep-W_"
      },
      "outputs": [],
      "source": [
        "option1='Atlanta Hartsfield International Airport'\n",
        "option2='Indianapolis International Airport'\n",
        "# p = nx.shortest_path(G,source=[i for i in airport_name if airport_name[i]==option1][0],target=[i for i in airport_name if airport_name[i]==option2][0], weight=\"l\")\n",
        "p=nx.shortest_path(G,source='ATL',target='IND',weight=\"l\")\n",
        "print(p)\n",
        "source=[i for i in airport_name if airport_name[i]==\"Atlanta Hartsfield International Airport \"]\n",
        "target=[i for i in airport_name if airport_name[i]==\"Indianapolis International Airport \"]\n",
        "print(source)\n",
        "print(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gH1RBc3p-XA"
      },
      "outputs": [],
      "source": [
        "#Remove Spaces from Airport Codes\n",
        "# for i in airport_name:\n",
        "\n",
        "#     airport_name[i]=airport_name[i].strip()\n",
        "# print(airport_name)\n",
        "#Remove Spaces from Airport Codes\n",
        "# for i in airport_name:\n",
        "#     #Remove Spaces from Airport Codes keys\n",
        "#     airport_name[i.strip()]=airport_name[i]\n",
        "# print(airport_name)\n",
        "print(airport_name['ATL']) # Remove trailing space from key\n",
        "for i in airport_name:\n",
        "    #Remove Spaces from Airport Codes keys\n",
        "    airport_name[i.strip()]=airport_name[i]\n",
        "print(airport_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap9_yM9ip-XA"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "airport_name={}\n",
        "with open ('US-Airport-Codes.csv', mode='r') as f:\n",
        "    data = csv.reader(f)\n",
        "    state_name={rows[1].strip():rows[2].strip() for rows in data}\n",
        "print(state_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IA3oyX-p-XA"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('state_code.pkl', 'wb') as f:\n",
        "    pickle.dump(state_name, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRJb4jMFp-XA"
      },
      "outputs": [],
      "source": [
        "state_name.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY80VHu6p-XA"
      },
      "outputs": [],
      "source": [
        "#Degree Of Particular Node\n",
        "G.degree('ATL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_WNjNz7p-XA"
      },
      "outputs": [],
      "source": [
        "temp={}\n",
        "for z in state_name:\n",
        "    if state_name[z]=='Alabama':\n",
        "        temp[z]=G.degree(z)\n",
        "temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc4nGBFGp-XA"
      },
      "outputs": [],
      "source": [
        "#Store Unique States\n",
        "uniqueValues = set(state_name.values())\n",
        "type(uniqueValues)\n",
        "type(list(uniqueValues))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBiwNiAVp-XA"
      },
      "outputs": [],
      "source": [
        "with open('graph.pkl', 'rb') as c:\n",
        "    nod = pickle.load(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sqm6d8sp-XA"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "import streamlit as st\n",
        "\n",
        "temp={}\n",
        "for z in state_name:\n",
        "    if state_name[z]=='Alabama':\n",
        "        temp[z]=nod.degree(z)\n",
        "temp\n",
        "st.write(temp) # Use st.write to display the dictionary in streamlit\n",
        "# Put Dictionary in Dataframe\n",
        "df = pd.DataFrame.from_dict(temp, orient='index', columns=['Degree'])\n",
        "# Print table\n",
        "st.write(df) # Use st.write to display the DataFrame in streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feZgym2lp-XA"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "airport_name={}\n",
        "with open ('US-STATE.csv', mode='r') as f:\n",
        "    data = csv.reader(f)\n",
        "    state_name2={rows[1].strip():rows[0].strip() for rows in data}\n",
        "print(state_name2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiVZw1k0p-XA"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('state_name2.pkl', 'wb') as f:\n",
        "    pickle.dump(state_name2, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlX06L6tp-XA"
      },
      "outputs": [],
      "source": [
        "list(state_name2.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ2Z8jKUp-XA"
      },
      "outputs": [],
      "source": [
        "state_name2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeDPE6J2p-XA"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('nearairport.pkl', 'wb') as m:\n",
        "    pickle.dump(shortestPathByDistanceTimeDF, m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai_EkNmup-XA"
      },
      "outputs": [],
      "source": [
        "print(type(shortestPathByDistanceTimeDF))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68qHpCzNp-XB"
      },
      "outputs": [],
      "source": [
        "shortestPathByDistanceTimeDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "996crXIqp-XB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert all values in the series to numeric, forcing errors to NaN\n",
        "series = pd.to_numeric(shortestPathByDistanceTimeDF['ATL'], errors='coerce')\n",
        "\n",
        "# Drop NaN values\n",
        "n = series.dropna().sort_values().head(100)\n",
        "\n",
        "# Convert series to dictionary\n",
        "n_dict = n.to_dict()\n",
        "\n",
        "# Convert all float values in the dictionary to int\n",
        "blank = {}\n",
        "for key, value in n_dict.items():\n",
        "    if pd.notna(value):  # Check if value is not NaN\n",
        "        blank[key] = int(value)\n",
        "    else:\n",
        "        blank[key] = None\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "df = pd.DataFrame.from_dict(blank, orient='index', columns=['Distance'])\n",
        "\n",
        "print(df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}